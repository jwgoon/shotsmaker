#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
shotsmaker main.py (single-file, stable)
- inputs/ ë‚´ ì´ë¯¸ì§€ë“¤ì„ ì´ì–´ë¶™ì—¬ ì„¸ë¡œí˜•(1080x1920) ì‡¼ì¸  ì˜ìƒ ìƒì„±
- Ken Burns(ëŠë¦° ì¤Œ) íš¨ê³¼
- ìë§‰: script.txt(ì¤„ ë‹¨ìœ„)ë¥¼ ìë™ ì½ì–´ ë¬¸ì¥ë³„ ìë§‰ êµ¬ì„± (ì—†ìœ¼ë©´ --caption í•œ ì¤„ ì‚¬ìš©)
- ì˜¤ë””ì˜¤: --audio íŒŒì¼ ì‚¬ìš©, ì—†ìœ¼ë©´ script/captionìœ¼ë¡œ gTTS ìë™ ìƒì„±(ì˜µì…˜)
- QuickTime/ì›¹ í˜¸í™˜: yuv420p + +faststart
- MoviePy 1.0.3/Pillow 9.5.0 í˜¸í™˜ (TextClip ì¸ìëª…: txt)

ì˜ˆì‹œ:
    python main.py --in inputs --out outputs --duration 5
    python main.py --in inputs --out outputs --duration 5 --caption "ë¹„í–‰ê¸° ì°½ë¬¸ ì•„ë˜ êµ¬ë©ì˜ ë¹„ë°€"
    python main.py --in inputs --out outputs --duration 5 --script inputs/script.txt
    python main.py --in inputs --out outputs --duration 5 --script inputs/script.txt --tts_lang ko
"""

from __future__ import annotations

import os
import sys
import argparse
import random
from pathlib import Path
from typing import List, Tuple, Optional

# MoviePy
from moviepy.editor import (
    ImageClip,
    ColorClip,
    CompositeVideoClip,
    TextClip,
    concatenate_videoclips,
    AudioFileClip,
)

# -----------------------------
# macOS í¸ì˜: ì™¸ë¶€ ë„êµ¬ ê²½ë¡œ íŒíŠ¸
# -----------------------------
if sys.platform == "darwin":
    os.environ.setdefault("IMAGEMAGICK_BINARY", "/opt/homebrew/bin/magick")
    os.environ.setdefault("IMAGEIO_FFMPEG_EXE", "/opt/homebrew/bin/ffmpeg")

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
RESOLUTION: Tuple[int, int] = (1080, 1920)  # ì„¸ë¡œ ìº”ë²„ìŠ¤
FPS: int = 30
BG_COLOR: Tuple[int, int, int] = (0, 0, 0)
KB_ZOOM_RANGE: Tuple[float, float] = (1.06, 1.16)  # 6~16% ì¤Œ ë²”ìœ„

# macOS / Windows í•œê¸€ í°íŠ¸ í›„ë³´
MAC_FONT_CANDIDATES: List[str] = [
    "/Library/Fonts/NanumGothic.ttf",
    "/System/Library/Fonts/AppleSDGothicNeo.ttc",
    "/System/Library/Fonts/Supplemental/AppleGothic.ttf",
]
WIN_FONT_CANDIDATES: List[str] = [
    "C:/Windows/Fonts/malgun.ttf",
    "C:/Windows/Fonts/malgunbd.ttf",
]


def pick_font_path() -> Optional[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì•„ ê²½ë¡œ ë°˜í™˜. ì—†ìœ¼ë©´ None."""
    candidates = MAC_FONT_CANDIDATES if sys.platform == "darwin" else WIN_FONT_CANDIDATES
    for p in candidates:
        if Path(p).exists():
            return p
    return None


# -----------------------------
# IO ìœ í‹¸
# -----------------------------
def ensure_dir(path: Path) -> None:
    path.mkdir(parents=True, exist_ok=True)


def scan_images(in_dir: Path) -> List[Path]:
    """ì…ë ¥ í´ë”(í•˜ìœ„ í¬í•¨)ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì¬ê·€ ê²€ìƒ‰."""
    exts = {".jpg", ".jpeg", ".png", ".webp", ".bmp", ".tiff", ".gif"}
    files = [p for p in in_dir.rglob("*") if p.is_file() and p.suffix.lower() in exts]
    files.sort()
    return files


def load_script_lines(in_dir: Path, script_arg: Optional[str]) -> List[str]:
    """
    ëŒ€ë³¸ íŒŒì¼ì„ ì¤„ ë‹¨ìœ„ë¡œ ì½ì–´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜.
    ìš°ì„ ìˆœìœ„: --script ê²½ë¡œ > {in_dir}/script.txt
    ë¹ˆ ì¤„ ì œê±°, ì–‘ë ê³µë°± ì œê±°.
    """
    target: Optional[Path] = None
    if script_arg:
        p = Path(script_arg)
        if p.exists():
            target = p
    else:
        p = in_dir / "script.txt"
        if p.exists():
            target = p

    if not target:
        return []

    lines: List[str] = []
    with open(target, "r", encoding="utf-8") as f:
        for line in f:
            s = line.strip()
            if s:
                lines.append(s)
    return lines


# -----------------------------
# ì˜ìƒ íš¨ê³¼
# -----------------------------
def ken_burns_for_image(
    img_path: Path,
    segment_duration: float,
    resolution: Tuple[int, int],
    bg_color: Tuple[int, int, int],
    zoom_range: Tuple[float, float] = KB_ZOOM_RANGE,
) -> CompositeVideoClip:
    """ì´ë¯¸ì§€ 1ì¥ì„ segment_duration ê¸¸ì´ì˜ ì¤Œ/íŒ¬ í´ë¦½ìœ¼ë¡œ ë³€í™˜."""
    base = ImageClip(str(img_path)).set_duration(max(0.01, float(segment_duration)))
    w0, h0 = base.size
    W, H = resolution

    # ìº”ë²„ìŠ¤ ì±„ìš°ê¸° ìœ„í•œ ìµœì†Œ ìŠ¤ì¼€ì¼
    sx, sy = W / w0, H / h0
    fill_scale = max(sx, sy)

    zmin, zmax = zoom_range
    start_scale = random.uniform(zmin, (zmin + zmax) / 2.0)
    end_scale = random.uniform((zmin + zmax) / 2.0, zmax)

    def scale_at(t: float) -> float:
        p = 0.0 if segment_duration <= 0 else min(max(t / segment_duration, 0.0), 1.0)
        return fill_scale * (start_scale + (end_scale - start_scale) * p)

    zoomed = base.resize(lambda t: scale_at(t))

    # ë°°ê²½ + ì¤‘ì•™ ì •ë ¬
    bg = ColorClip(resolution, color=bg_color).set_duration(segment_duration)
    clip = CompositeVideoClip([bg, zoomed.set_position("center")], size=resolution)
    return clip.set_duration(segment_duration)


# -----------------------------
# ìë§‰
# -----------------------------
def make_caption_clip(
    text: str,
    duration: float,
    resolution: Tuple[int, int],
    font_path: Optional[str],
    fontsize: int = 56,
    color: Tuple[int, int, int] = (255, 255, 255),
    stroke_width: int = 2,
    stroke_color: Tuple[int, int, int] = (0, 0, 0),
    margin_bottom: int = 120,
) -> TextClip:
    """í•œ ì¤„ ìë§‰ í´ë¦½ (moviepy 1.0.3 â†’ TextClip ì¸ìëª…ì€ txt)."""
    color_str = f"rgb({color[0]},{color[1]},{color[2]})"
    stroke_str = f"rgb({stroke_color[0]},{stroke_color[1]},{stroke_color[2]})"

    base_kwargs = dict(
        txt=text,                 # í•µì‹¬: 'text'ê°€ ì•„ë‹ˆë¼ 'txt'
        fontsize=fontsize,
        color=color_str,
        stroke_color=stroke_str,
        stroke_width=stroke_width,
    )
    if font_path:
        base_kwargs["font"] = font_path

    # caption ë°©ì‹(ìë™ ì¤„ë°”ê¿ˆ) â†’ ì‹¤íŒ¨ ì‹œ label í´ë°±
    try:
        tc = TextClip(
            **base_kwargs,
            method="caption",
            size=(resolution[0] - 100, None),
        ).set_duration(max(0.01, float(duration)))
    except Exception:
        safe = text
        if len(safe) > 40:
            parts = [safe[i:i + 40] for i in range(0, len(safe), 40)]
            safe = "\n".join(parts)
        fb = dict(base_kwargs)
        fb["txt"] = safe
        tc = TextClip(**fb, method="label").set_duration(max(0.01, float(duration)))

    return tc.set_position(("center", resolution[1] - margin_bottom))


def make_caption_sequence(
    lines: List[str],
    total_duration: float,
    resolution: Tuple[int, int],
    font_path: Optional[str],
) -> List[TextClip]:
    """
    ëŒ€ë³¸ ì¤„ ë³„ë¡œ ìë§‰ í´ë¦½ì„ ë§Œë“¤ê³  total_duration ë‚´ì—ì„œ ìˆœì°¨ ë°°ì¹˜.
    ê¸°ë³¸ ì‹œê°„: ê¸€ììˆ˜*0.06ì´ˆ(ìµœì†Œ 1.2ì´ˆ) â†’ ì „ì²´ ê¸¸ì´ì— ë§ì¶° ë¹„ìœ¨ ìŠ¤ì¼€ì¼.
    """
    if not lines:
        return []

    raw_durs = [max(1.2, len(line) * 0.06) for line in lines]
    sum_raw = sum(raw_durs)
    factor = total_duration / sum_raw if sum_raw > 0 else 1.0
    durs = [max(0.8, rd * factor) for rd in raw_durs]

    # ëˆ„ì  ì‹œì‘ ì‹œê°
    starts, acc = [], 0.0
    for d in durs:
        starts.append(acc)
        acc += d

    # ë§ˆì§€ë§‰ ì¡°ì •
    if acc > 0 and abs(acc - total_duration) > 0.25:
        scale = total_duration / acc
        durs = [d * scale for d in durs]
        starts, acc = [], 0.0
        for d in durs:
            starts.append(acc)
            acc += d

    color_str = "rgb(255,255,255)"
    stroke_str = "rgb(0,0,0)"
    seq: List[TextClip] = []

    for line, st, du in zip(lines, starts, durs):
        kwargs = dict(
            txt=line,
            fontsize=56,
            color=color_str,
            stroke_color=stroke_str,
            stroke_width=2,
            method="caption",
            size=(resolution[0] - 100, None),
        )
        if font_path:
            kwargs["font"] = font_path

        try:
            tc = TextClip(**kwargs).set_duration(du)
        except Exception:
            safe = line
            if len(safe) > 40:
                parts = [safe[i:i + 40] for i in range(0, len(safe), 40)]
                safe = "\n".join(parts)
            kw = dict(kwargs)
            kw["txt"] = safe
            kw.pop("size", None)
            kw["method"] = "label"
            tc = TextClip(**kw).set_duration(du)

        tc = tc.set_position(("center", RESOLUTION[1] - 120)).set_start(st)
        seq.append(tc)

    return seq


# -----------------------------
# ìµœì¢… í•©ì„± / ì¶œë ¥
# -----------------------------
def build_final_video(
    images: List[Path],
    per_image_sec: float,
    caption_text: Optional[str],
    audio_path: Optional[Path],
    script_lines: Optional[List[str]] = None,
) -> CompositeVideoClip:
    """ì´ë¯¸ì§€ â†’ í´ë¦½ â†’ ì—°ê²°, ìë§‰/ì˜¤ë””ì˜¤ ì ìš©."""
    if not images:
        raise SystemExit("âŒ inputs í´ë”ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    clips = [
        ken_burns_for_image(
            img_path=img,
            segment_duration=per_image_sec,
            resolution=RESOLUTION,
            bg_color=BG_COLOR,
            zoom_range=KB_ZOOM_RANGE,
        )
        for img in images
    ]
    video = concatenate_videoclips(clips, method="compose")

    # ìë§‰: script_lines ìš°ì„ , ì—†ìœ¼ë©´ caption_text(í•œ ì¤„)
    if script_lines and len(script_lines) > 0:
        font_path = pick_font_path()
        seq = make_caption_sequence(
            lines=script_lines,
            total_duration=video.duration,
            resolution=RESOLUTION,
            font_path=font_path,
        )
        if seq:
            video = CompositeVideoClip([video, *seq], size=RESOLUTION)
    elif caption_text:
        font_path = pick_font_path()
        cap = make_caption_clip(
            text=caption_text,
            duration=video.duration,
            resolution=RESOLUTION,
            font_path=font_path,
            fontsize=56,
            color=(255, 255, 255),
            stroke_width=2,
            stroke_color=(0, 0, 0),
            margin_bottom=120,
        )
        video = CompositeVideoClip([video, cap], size=RESOLUTION)

    # ì˜¤ë””ì˜¤
    if audio_path and audio_path.exists():
        try:
            ac = AudioFileClip(str(audio_path))
            video = video.set_audio(ac)
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")

    return video.set_fps(FPS)


def write_video_safe(clip: CompositeVideoClip, out_path: Path) -> None:
    """ì¬ìƒ í˜¸í™˜ì„ ìœ„í•œ ì•ˆì „í•œ ì¸ì½”ë”© ì˜µì…˜ ê³ ì •."""
    ensure_dir(out_path.parent)
    if not clip.duration or clip.duration <= 0:
        raise SystemExit("âŒ ìµœì¢… í´ë¦½ ê¸¸ì´ê°€ 0ì´ˆì…ë‹ˆë‹¤. --duration(ì¥ë‹¹ ê¸¸ì´)ì„ í™•ì¸í•˜ì„¸ìš”.")

    print(f"\nâ¡ï¸  ìµœì¢… ê¸¸ì´: {clip.duration:.2f}s, FPS: {FPS}, ì¶œë ¥: {out_path}\n")

    clip.write_videofile(
        str(out_path),
        fps=FPS,
        codec="libx264",
        audio_codec="aac",
        bitrate="4000k",
        ffmpeg_params=["-pix_fmt", "yuv420p", "-movflags", "+faststart"],
        threads=max(1, (os.cpu_count() or 8) - 1),
        verbose=True,
        logger="bar",  # ì§„í–‰ë°” í‘œì‹œ ("print"/None ë„ ê°€ëŠ¥)
    )


# -----------------------------
# CLI
# -----------------------------
def build_arg_parser() -> argparse.ArgumentParser:
    ap = argparse.ArgumentParser()
    ap.add_argument("--in", dest="in_dir", default="inputs", help="ì…ë ¥ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ")
    ap.add_argument("--out", dest="out_dir", default="outputs", help="ì¶œë ¥ í´ë” ê²½ë¡œ")
    ap.add_argument("--tts-lang", "--tts_lang", dest="tts_lang", default="ko", help="TTS ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko, en)")
    ap.add_argument("--duration", type=float, default=3.0, help="ì´ë¯¸ì§€ 1ì¥ë‹¹ ì§€ì† ì‹œê°„(ì´ˆ)")
    ap.add_argument("--caption", type=str, default=None, help="(ì˜µì…˜) ì „ì²´ êµ¬ê°„ í•œ ì¤„ ìë§‰")
    ap.add_argument("--audio", type=str, default=None, help="(ì˜µì…˜) ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ(mp3/wav)")
    ap.add_argument("--script", type=str, default=None, help="(ì˜µì…˜) ëŒ€ë³¸ íŒŒì¼ ê²½ë¡œ(ë¯¸ì§€ì •ì‹œ inputs/script.txt ì‹œë„)")
    return ap


def main() -> None:
    from gtts import gTTS
    import tempfile

    # 1) ì¸ì
    ap = build_arg_parser()
    args = ap.parse_args()

    # 2) ê²½ë¡œ
    in_dir = Path(args.in_dir)
    out_dir = Path(args.out_dir)
    out_path = out_dir / "output.mp4"

    if not in_dir.exists():
        raise SystemExit(f"âŒ ì…ë ¥ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {in_dir}")

    # 3) ì´ë¯¸ì§€ ìŠ¤ìº”
    images = scan_images(in_dir)
    if not images:
        raise SystemExit(f"âŒ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {in_dir} (ì˜ˆ: {in_dir}/image.png ë˜ëŠ” í•˜ìœ„ í´ë”)")

    # 4) ìŠ¤í¬ë¦½íŠ¸/ì˜µì…˜
    per_image_sec = max(0.1, float(args.duration))
    caption_text = args.caption
    script_lines = load_script_lines(in_dir, args.script)
    audio_path = Path(args.audio) if args.audio else None

    # 5) ìë™ TTS: ì˜¤ë””ì˜¤ ì—†ê³  ìŠ¤í¬ë¦½íŠ¸ or ìº¡ì…˜ ìˆìœ¼ë©´ ìƒì„±
    if audio_path is None and (script_lines or caption_text):
        try:
            tmpdir = Path(tempfile.gettempdir())
            tts_path = tmpdir / "shotsmaker_tts.mp3"
            tts_text = " ".join(script_lines) if script_lines else caption_text
            tts = gTTS(text=tts_text, lang=(args.tts_lang or "ko"))
            tts.save(str(tts_path))
            audio_path = tts_path
            print(f"ğŸ”Š TTS ìƒì„± ì™„ë£Œ â†’ {tts_path}")
        except Exception as e:
            print(f"âš ï¸ TTS ìƒì„± ì‹¤íŒ¨: {e} (ë¬´ìŒìœ¼ë¡œ ì§„í–‰)")

    # 6) í•©ì„± & ì €ì¥
    final_clip = build_final_video(
        images=images,
        per_image_sec=per_image_sec,
        caption_text=caption_text,
        audio_path=audio_path,
        script_lines=script_lines,
    )
    write_video_safe(final_clip, out_path)
    print("\nâœ… ì™„ë£Œ! ì¬ìƒì´ ì•ˆ ë˜ë©´ VLCë¡œë„ í…ŒìŠ¤íŠ¸í•´ ë³´ì„¸ìš” (QuickTime ë¬¸ì œì¼ ìˆ˜ ìˆìŒ).\n")


if __name__ == "__main__":
    main()
